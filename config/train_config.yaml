# Crickformer Training Configuration
# Author: Assistant, Last Modified: 2024

# Training Parameters
batch_size: 32
num_epochs: 10
learning_rate: 1e-4
log_interval: 100

# Loss Weights for Multi-Task Learning
loss_weights:
  win_prob: 1.0        # Win probability prediction
  outcome: 1.0         # Next ball outcome prediction
  mispricing: 0.5      # Odds mispricing detection

# Model Architecture Configuration
model:
  sequence_encoder:
    feature_dim: 64      # Ball history feature dimension (updated for memory efficiency)
    nhead: 4             # Multi-head attention heads (64 divisible by 4 = 16 dims per head)
    num_encoder_layers: 2 # Number of transformer layers
    dim_feedforward: 256  # Feedforward dimension
    dropout: 0.1         # Dropout rate
    
  static_context_encoder:
    numeric_dim: 15      # 15 numeric features
    categorical_vocab_sizes:
      competition: 100
      batter_hand: 100
      bowler_type: 100
      innings: 10
    categorical_embedding_dims:
      competition: 8
      batter_hand: 4
      bowler_type: 8
      innings: 4
    video_dim: 99        # Video features dimension
    weather_dim: 6       # Weather features (temp, humidity, wind, etc.)
    venue_coord_dim: 2   # Venue coordinates (lat, lon)
    hidden_dims: [128, 64]  # Hidden layer dimensions
    context_dim: 128     # Output embedding dimension
    dropout_rate: 0.1    # Dropout rate
    
  fusion_layer:
    sequence_dim: 64     # Sequence encoder output dimension
    context_dim: 128     # Static context encoder output dimension  
    kg_dim: 128          # KG attention output dimension
    hidden_dims: [256, 128]  # Hidden layer dimensions
    latent_dim: 128      # Final embedding dimension
    dropout_rate: 0.1    # Dropout rate
    
  prediction_heads:
    win_probability:
      latent_dim: 128    # Input from fusion layer
      dropout_rate: 0.1  # Dropout rate
      
    next_ball_outcome:
      latent_dim: 128    # Input from fusion layer
      num_outcomes: 7    # 0,1,2,3,4,6,wicket
      dropout_rate: 0.1  # Dropout rate
      
    odds_mispricing:
      latent_dim: 128    # Input from fusion layer
      dropout_rate: 0.1  # Dropout rate

# Dataset Configuration
dataset:
  history_length: 5      # Number of recent balls to include
  load_video: true       # Load video signals
  load_embeddings: true  # Load GNN embeddings
  load_market_odds: true # Load market odds data
  
# Optimization Configuration
optimizer:
  type: "adam"           # Optimizer type
  weight_decay: 1e-5     # L2 regularization
  
# Learning Rate Scheduling
scheduler:
  type: "reduce_on_plateau"
  factor: 0.5            # Reduction factor
  patience: 3            # Epochs to wait before reducing
  min_lr: 1e-6           # Minimum learning rate
  
# Regularization
regularization:
  gradient_clip_norm: 1.0  # Gradient clipping max norm
  
# Hardware Configuration
hardware:
  device: "auto"         # auto, cpu, cuda
  num_workers: 2         # DataLoader workers
  pin_memory: true       # Pin memory for faster GPU transfer
  
# Logging Configuration
logging:
  log_level: "INFO"      # Logging level
  save_interval: 1000    # Save model every N steps
  eval_interval: 500     # Evaluate every N steps
  
# Model Saving
checkpointing:
  save_best: true        # Save best model based on validation loss
  save_last: true        # Save last model
  monitor: "val_loss"    # Metric to monitor for best model 