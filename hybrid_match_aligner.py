# Purpose: Hybrid match aligner combining LLM intelligence with traditional fuzzy logic
# Author: Assistant, Last Modified: 2024

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
import logging
import json
from dataclasses import dataclass
from difflib import SequenceMatcher
import Levenshtein
import os

# Try to import env_manager for better integration
try:
    from env_manager import get_env_manager
    ENV_MANAGER_AVAILABLE = True
except ImportError:
    ENV_MANAGER_AVAILABLE = False

logger = logging.getLogger(__name__)

@dataclass
class HybridConfig:
    """Configuration generated by LLM for traditional fuzzy matching."""
    column_mapping: Dict[str, Dict[str, str]]
    similarity_threshold: float
    fingerprint_length: int
    name_normalization_rules: List[str]
    weight_factors: Dict[str, float]
    reasoning: str
    confidence: float

class HybridMatchAligner:
    """
    Hybrid match aligner that uses LLM for configuration and traditional fuzzy logic for matching.
    
    Benefits:
    - LLM analyzes data structure and suggests optimal configuration (one-time cost)
    - Traditional fuzzy logic performs actual matching (fast, offline)
    - Best of both worlds: intelligence + performance
    - Integrates with WicketWise env_manager for secure API key handling
    """
    
    def __init__(self, nvplay_path: str, decimal_path: str, openai_api_key: Optional[str] = None):
        self.nvplay_path = Path(nvplay_path)
        self.decimal_path = Path(decimal_path)
        
        # Get OpenAI API key from multiple sources
        self.openai_api_key = self._get_openai_api_key(openai_api_key)
        
        # Load data
        self.nvplay_df = pd.read_csv(self.nvplay_path)
        self.decimal_df = pd.read_csv(self.decimal_path)
        
        # Configuration
        self.config: Optional[HybridConfig] = None
        
        logger.info(f"Loaded NVPlay data: {len(self.nvplay_df)} records")
        logger.info(f"Loaded Decimal data: {len(self.decimal_df)} records")
        
        # Log API key status
        if self.openai_api_key:
            logger.info("✅ OpenAI API key available for LLM configuration")
        else:
            logger.info("⚠️  No OpenAI API key found, will use fallback configuration")
    
    def _get_openai_api_key(self, provided_key: Optional[str] = None) -> Optional[str]:
        """Get OpenAI API key from multiple sources with priority order."""
        
        # Priority 1: Explicitly provided key
        if provided_key:
            return provided_key
        
        # Priority 2: Use env_manager if available
        if ENV_MANAGER_AVAILABLE:
            try:
                env_manager = get_env_manager()
                openai_key = env_manager.get_api_key('openai')
                if openai_key:
                    logger.info("🔑 Using OpenAI API key from env_manager")
                    return openai_key
            except Exception as e:
                logger.debug(f"Could not get key from env_manager: {e}")
        
        # Priority 3: Check environment variables directly
        env_key = os.getenv('OPENAI_API_KEY')
        if env_key:
            logger.info("🔑 Using OpenAI API key from environment variable")
            return env_key
        
        # Priority 4: Load from .env file
        try:
            from dotenv import load_dotenv
            load_dotenv()
            env_key = os.getenv('OPENAI_API_KEY')
            if env_key:
                logger.info("🔑 Using OpenAI API key from .env file")
                return env_key
        except ImportError:
            logger.debug("python-dotenv not available, skipping .env file loading")
        
        return None
    
    def generate_llm_configuration(self) -> HybridConfig:
        """Use LLM to generate optimal configuration for traditional fuzzy matching."""
        
        if not self.openai_api_key:
            logger.warning("No OpenAI API key provided, using fallback configuration")
            self.config = self._fallback_configuration()
            return self.config
        
        try:
            import openai
            client = openai.OpenAI(api_key=self.openai_api_key)
            
            # Analyze data structure
            nvplay_info = {
                "columns": list(self.nvplay_df.columns),
                "sample": self.nvplay_df.head(2).to_dict('records'),
                "match_count": self.nvplay_df['Match'].nunique() if 'Match' in self.nvplay_df.columns else 0
            }
            
            decimal_info = {
                "columns": list(self.decimal_df.columns),
                "sample": self.decimal_df.head(2).to_dict('records'),
                "match_count": len(self.decimal_df.groupby(['home', 'away', 'date'])) if all(col in self.decimal_df.columns for col in ['home', 'away', 'date']) else 0
            }
            
            prompt = f"""
            Analyze these cricket datasets and generate configuration for traditional fuzzy matching.
            
            NVPLAY DATA: {json.dumps(nvplay_info, indent=2)}
            DECIMAL DATA: {json.dumps(decimal_info, indent=2)}
            
            Generate configuration for traditional fuzzy matching algorithm that will:
            1. Map columns correctly between datasets
            2. Suggest optimal similarity threshold
            3. Recommend fingerprint length (balls to compare)
            4. Provide name normalization rules
            5. Set weight factors for different similarity components
            
            Return JSON:
            {{
                "column_mapping": {{
                    "nvplay": {{"match_id": "Match", "batter": "Batter", ...}},
                    "decimal": {{"match_id": "transformation", "batter": "batsman", ...}}
                }},
                "similarity_threshold": 0.75,
                "fingerprint_length": 20,
                "name_normalization_rules": ["remove_dots", "uppercase", "remove_spaces"],
                "weight_factors": {{"player_names": 0.4, "runs_pattern": 0.3, "ball_sequence": 0.3}},
                "reasoning": "Detailed explanation",
                "confidence": 0.85
            }}
            """
            
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1
            )
            
            result = json.loads(response.choices[0].message.content)
            
            self.config = HybridConfig(
                column_mapping=result["column_mapping"],
                similarity_threshold=result["similarity_threshold"],
                fingerprint_length=result["fingerprint_length"],
                name_normalization_rules=result["name_normalization_rules"],
                weight_factors=result["weight_factors"],
                reasoning=result["reasoning"],
                confidence=result["confidence"]
            )
            
            logger.info(f"LLM Configuration generated (confidence: {self.config.confidence:.2f})")
            logger.info(f"Reasoning: {self.config.reasoning}")
            
            return self.config
            
        except Exception as e:
            logger.error(f"LLM configuration failed: {e}")
            return self._fallback_configuration()
    
    def normalize_name(self, name: str) -> str:
        """Apply normalization rules to player names."""
        if not self.config:
            return name.strip().upper()
        
        normalized = str(name)
        for rule in self.config.name_normalization_rules:
            if rule == "remove_dots":
                normalized = normalized.replace('.', '')
            elif rule == "uppercase":
                normalized = normalized.upper()
            elif rule == "remove_spaces":
                normalized = normalized.replace(' ', '')
            elif rule == "remove_initials":
                # Remove single letters followed by space
                import re
                normalized = re.sub(r'\b[A-Z]\s+', '', normalized)
        
        return normalized.strip()
    
    def fuzzy_name_similarity(self, name1: str, name2: str) -> float:
        """Calculate fuzzy similarity between player names with enhanced cricket-specific matching."""
        
        # Handle None or empty names
        if not name1 or not name2:
            return 0.0
        
        # Convert to strings and strip whitespace
        name1, name2 = str(name1).strip(), str(name2).strip()
        
        # Exact match after normalization
        norm1 = self.normalize_name(name1)
        norm2 = self.normalize_name(name2)
        
        if norm1 == norm2:
            return 1.0
        
        # Cricket-specific name matching
        cricket_similarity = self._calculate_cricket_name_similarity(name1, name2)
        if cricket_similarity > 0.9:
            return cricket_similarity
        
        # Traditional fuzzy matching with improved weights
        sequence_sim = SequenceMatcher(None, norm1, norm2).ratio()
        levenshtein_sim = 1 - (Levenshtein.distance(norm1, norm2) / max(len(norm1), len(norm2)))
        
        # Combine all similarities with cricket-specific boost
        base_similarity = 0.5 * sequence_sim + 0.3 * levenshtein_sim + 0.2 * cricket_similarity
        
        return min(1.0, base_similarity)
    
    def _calculate_cricket_name_similarity(self, name1: str, name2: str) -> float:
        """Calculate cricket-specific name similarity handling initials and common patterns."""
        
        # Parse names into components
        parts1 = self._parse_cricket_name(name1)
        parts2 = self._parse_cricket_name(name2)
        
        # Handle initial matching (e.g., "JR Philippe" vs "Josh Philippe")
        initial_match = self._match_initials_to_names(parts1, parts2)
        if initial_match > 0.8:
            return initial_match
        
        # Handle reversed name order (e.g., "Smith John" vs "John Smith")
        reversed_match = self._match_reversed_names(parts1, parts2)
        if reversed_match > 0.8:
            return reversed_match
        
        # Handle common cricket name patterns
        pattern_match = self._match_cricket_patterns(parts1, parts2)
        
        return max(initial_match, reversed_match, pattern_match)
    
    def _parse_cricket_name(self, name: str) -> Dict:
        """Parse cricket player name into components."""
        
        parts = name.strip().split()
        
        # Identify initials and full names
        initials = []
        full_names = []
        
        for part in parts:
            clean_part = part.replace('.', '').strip()
            
            # Check if it's initials (single letter or 2-3 uppercase letters)
            if len(clean_part) == 1 and clean_part.isalpha():
                initials.append(clean_part.upper())
            elif (len(clean_part) <= 3 and 
                  clean_part.isupper() and 
                  clean_part.isalpha() and 
                  not self._is_likely_full_name(clean_part)):
                initials.append(clean_part.upper())
            elif len(clean_part) > 1:
                full_names.append(clean_part)
        
        return {
            'initials': initials,
            'full_names': full_names,
            'all_parts': parts,
            'normalized': self.normalize_name(name)
        }
    
    def _is_likely_full_name(self, word: str) -> bool:
        """Check if a short word is likely a full name rather than initials."""
        
        # Common short cricket names that aren't initials
        short_names = {
            'ALI', 'ROY', 'LEE', 'RAY', 'JAY', 'KAY', 'MAX', 'SAM', 'TOM', 'JOE', 'BOB'
        }
        
        return word.upper() in short_names
    
    def _match_initials_to_names(self, parts1: Dict, parts2: Dict) -> float:
        """Match initials to full names (e.g., JR vs Josh)."""
        
        # Check if one has initials and other has full names
        if parts1['initials'] and parts2['full_names']:
            return self._check_initial_match(parts1, parts2)
        elif parts2['initials'] and parts1['full_names']:
            return self._check_initial_match(parts2, parts1)
        
        return 0.0
    
    def _check_initial_match(self, initial_parts: Dict, full_parts: Dict) -> float:
        """Check if initials match full names with improved logic."""
        
        matches = 0
        total_initials = len(initial_parts['initials'])
        
        if total_initials == 0:
            return 0.0
        
        for initial in initial_parts['initials']:
            # Handle compound initials (e.g., "JR" could be "Josh Robert" or just "J")
            if len(initial) == 2:
                # Try matching first letter to first name
                first_letter = initial[0]
                for full_name in full_parts['full_names']:
                    if full_name.upper().startswith(first_letter):
                        matches += 1
                        break
            elif len(initial) == 1:
                # Single initial matching
                for full_name in full_parts['full_names']:
                    if full_name.upper().startswith(initial):
                        matches += 1
                        break
            else:
                # Multiple initials in one string (e.g., "JRM")
                matched_count = 0
                for letter in initial:
                    for full_name in full_parts['full_names']:
                        if full_name.upper().startswith(letter):
                            matched_count += 1
                            break
                # Partial credit for multiple initial matching
                matches += matched_count / len(initial)
        
        # Check if surnames match
        surname_match = 0
        if initial_parts['full_names'] and full_parts['full_names']:
            # Assume last name is surname
            surname1 = initial_parts['full_names'][-1].upper()
            surname2 = full_parts['full_names'][-1].upper()
            
            if surname1 == surname2:
                surname_match = 1
            else:
                # Fuzzy surname matching
                surname_sim = SequenceMatcher(None, surname1, surname2).ratio()
                if surname_sim > 0.8:
                    surname_match = surname_sim
        
        # Combine initial matching with surname matching
        initial_score = matches / total_initials
        
        # If we have a perfect surname match, give more weight to it
        if surname_match == 1:
            final_score = 0.4 * initial_score + 0.6 * surname_match
        else:
            final_score = 0.6 * initial_score + 0.4 * surname_match
        
        return final_score
    
    def _match_reversed_names(self, parts1: Dict, parts2: Dict) -> float:
        """Match names that might be in different order."""
        
        all_parts1 = set(p.upper() for p in parts1['all_parts'])
        all_parts2 = set(p.upper() for p in parts2['all_parts'])
        
        # Calculate Jaccard similarity
        intersection = len(all_parts1 & all_parts2)
        union = len(all_parts1 | all_parts2)
        
        if union == 0:
            return 0.0
        
        return intersection / union
    
    def _match_cricket_patterns(self, parts1: Dict, parts2: Dict) -> float:
        """Match common cricket name patterns and abbreviations."""
        
        # Common cricket name mappings
        cricket_mappings = {
            'MOHAMMED': ['MOHAMMAD', 'MOHAMED', 'MUHAMMED'],
            'ABDUL': ['ABD', 'ABDEL'],
            'KRISHNA': ['KRISH'],
            'SURESH': ['SURI'],
            'CAPTAIN': ['CAPT', 'C'],
            'JUNIOR': ['JR', 'JNR'],
            'SENIOR': ['SR', 'SNR']
        }
        
        # Check if any parts match known cricket patterns
        pattern_matches = 0
        total_comparisons = 0
        
        for name1 in parts1['all_parts']:
            for name2 in parts2['all_parts']:
                total_comparisons += 1
                name1_upper = name1.upper().replace('.', '')
                name2_upper = name2.upper().replace('.', '')
                
                # Direct match
                if name1_upper == name2_upper:
                    pattern_matches += 1
                    continue
                
                # Check mapping patterns
                for standard, variations in cricket_mappings.items():
                    if ((name1_upper == standard and name2_upper in variations) or
                        (name2_upper == standard and name1_upper in variations) or
                        (name1_upper in variations and name2_upper in variations)):
                        pattern_matches += 0.9
                        break
        
        if total_comparisons == 0:
            return 0.0
        
        return pattern_matches / total_comparisons
    
    def extract_fingerprints(self) -> Tuple[Dict[str, List], Dict[str, List]]:
        """Extract fingerprints using LLM-configured column mappings."""
        
        if not self.config:
            self.config = self.generate_llm_configuration()
        
        nvplay_fps = {}
        decimal_fps = {}
        
        # Extract NVPlay fingerprints
        nvplay_mapping = self.config.column_mapping["nvplay"]
        for match_id in self.nvplay_df[nvplay_mapping['match_id']].unique():
            match_data = self.nvplay_df[self.nvplay_df[nvplay_mapping['match_id']] == match_id]
            match_data = match_data.sort_values([nvplay_mapping['innings'], nvplay_mapping['over'], nvplay_mapping['ball']])
            
            fingerprint = []
            for _, row in match_data.head(self.config.fingerprint_length).iterrows():
                fingerprint.append({
                    'over': row[nvplay_mapping['over']],
                    'ball': row[nvplay_mapping['ball']],
                    'batter': row[nvplay_mapping['batter']],
                    'bowler': row[nvplay_mapping['bowler']],
                    'runs': row[nvplay_mapping['runs']],
                    'innings': row[nvplay_mapping['innings']]
                })
            
            nvplay_fps[match_id] = fingerprint
        
        # Extract Decimal fingerprints
        decimal_mapping = self.config.column_mapping["decimal"]
        
        # Create match identifiers for decimal data
        if decimal_mapping['match_id'] == 'date':
            # Group by date, home, away, and competition for unique match identification
            self.decimal_df['match_id'] = (
                self.decimal_df['date'].astype(str) + '_' +
                self.decimal_df['home'].astype(str) + '_vs_' +
                self.decimal_df['away'].astype(str) + '_' +
                self.decimal_df['competition'].astype(str)
            )
            match_id_col = 'match_id'
        elif decimal_mapping['match_id'] == 'transformation':
            self.decimal_df['match_id'] = (
                self.decimal_df['competition'].astype(str) + '_' +
                self.decimal_df['home'].astype(str) + '_vs_' +
                self.decimal_df['away'].astype(str) + '_' +
                self.decimal_df['date'].astype(str)
            )
            match_id_col = 'match_id'
        else:
            match_id_col = decimal_mapping['match_id']
        
        for match_id in self.decimal_df[match_id_col].unique():
            match_data = self.decimal_df[self.decimal_df[match_id_col] == match_id]
            match_data = match_data.sort_values([decimal_mapping['innings'], decimal_mapping['over'], decimal_mapping['ball']])
            
            fingerprint = []
            for _, row in match_data.head(self.config.fingerprint_length).iterrows():
                # Handle over/ball extraction
                if decimal_mapping['over'] == 'over' and decimal_mapping['ball'] == 'delivery':
                    # Direct column mapping
                    over = row[decimal_mapping['over']]
                    ball = row[decimal_mapping['ball']]
                else:
                    # Parse ball number
                    ball_info = self._parse_ball_number(row[decimal_mapping['ball']])
                    over = ball_info['over']
                    ball = ball_info['ball']
                
                fingerprint.append({
                    'over': over,
                    'ball': ball,
                    'batter': row[decimal_mapping['batter']],
                    'bowler': row[decimal_mapping['bowler']],
                    'runs': row[decimal_mapping['runs']],
                    'innings': row[decimal_mapping['innings']]
                })
            
            decimal_fps[match_id] = fingerprint
        
        return nvplay_fps, decimal_fps
    
    def calculate_fuzzy_similarity(self, fp1: List[Dict], fp2: List[Dict]) -> float:
        """Calculate fuzzy similarity between fingerprints with improved algorithm."""
        
        if not fp1 or not fp2:
            return 0.0
        
        # Use dynamic programming to find best alignment between sequences
        similarity_matrix = self._calculate_alignment_similarity(fp1, fp2)
        
        # Also calculate traditional position-based similarity for comparison
        position_similarity = self._calculate_position_similarity(fp1, fp2)
        
        # Combine alignment-based and position-based similarities
        alignment_weight = 0.7
        position_weight = 0.3
        
        final_similarity = (alignment_weight * similarity_matrix + 
                          position_weight * position_similarity)
        
        return final_similarity
    
    def _calculate_alignment_similarity(self, fp1: List[Dict], fp2: List[Dict]) -> float:
        """Calculate similarity using dynamic programming for best sequence alignment."""
        
        if not fp1 or not fp2:
            return 0.0
        
        # Create similarity matrix for dynamic programming
        m, n = len(fp1), len(fp2)
        dp = [[0.0 for _ in range(n + 1)] for _ in range(m + 1)]
        
        # Fill the matrix
        for i in range(1, m + 1):
            for j in range(1, n + 1):
                # Calculate ball-to-ball similarity
                ball_sim = self._calculate_ball_similarity(fp1[i-1], fp2[j-1])
                
                # Consider three options: match, skip from fp1, skip from fp2
                match_score = dp[i-1][j-1] + ball_sim
                skip1_score = dp[i-1][j] + 0.1  # Small penalty for skipping
                skip2_score = dp[i][j-1] + 0.1  # Small penalty for skipping
                
                dp[i][j] = max(match_score, skip1_score, skip2_score)
        
        # Normalize by the maximum possible score
        max_possible = min(m, n)
        return dp[m][n] / max_possible if max_possible > 0 else 0.0
    
    def _calculate_position_similarity(self, fp1: List[Dict], fp2: List[Dict]) -> float:
        """Calculate traditional position-based similarity."""
        
        if not fp1 or not fp2:
            return 0.0
        
        min_length = min(len(fp1), len(fp2))
        weights = self.config.weight_factors
        total_score = 0.0
        
        for i in range(min_length):
            ball1, ball2 = fp1[i], fp2[i]
            ball_similarity = self._calculate_ball_similarity(ball1, ball2)
            total_score += ball_similarity
        
        return total_score / min_length
    
    def _calculate_ball_similarity(self, ball1: Dict, ball2: Dict) -> float:
        """Calculate similarity between two individual balls with improved algorithm."""
        
        weights = self.config.weight_factors
        
        # Player name similarity (fuzzy)
        batter_sim = self.fuzzy_name_similarity(ball1['batter'], ball2['batter'])
        bowler_sim = self.fuzzy_name_similarity(ball1['bowler'], ball2['bowler'])
        player_score = (batter_sim + bowler_sim) / 2
        
        # Ball sequence similarity (more flexible)
        sequence_score = self._calculate_sequence_similarity(ball1, ball2)
        
        # Runs pattern similarity (fuzzy)
        runs_score = self._calculate_runs_similarity(ball1['runs'], ball2['runs'])
        
        # Match context similarity (exact)
        context_score = 1.0 if ball1['innings'] == ball2['innings'] else 0.0
        
        # Weighted combination with improved weights
        ball_similarity = (
            weights.get('player_names', 0.5) * player_score +
            weights.get('ball_sequence', 0.2) * sequence_score +
            weights.get('runs_pattern', 0.2) * runs_score +
            weights.get('match_context', 0.1) * context_score
        )
        
        return ball_similarity
    
    def _calculate_sequence_similarity(self, ball1: Dict, ball2: Dict) -> float:
        """Calculate more flexible sequence similarity."""
        
        over1, over2 = ball1['over'], ball2['over']
        ball_num1, ball_num2 = ball1['ball'], ball2['ball']
        
        # Exact match gets full score
        if over1 == over2 and ball_num1 == ball_num2:
            return 1.0
        
        # Same over but different ball gets partial score
        if over1 == over2:
            ball_diff = abs(ball_num1 - ball_num2)
            return max(0.0, 1.0 - (ball_diff * 0.2))
        
        # Different over but close gets some score
        over_diff = abs(over1 - over2)
        if over_diff <= 1:
            return max(0.0, 0.5 - (over_diff * 0.3))
        
        return 0.0
    
    def _calculate_runs_similarity(self, runs1: int, runs2: int) -> float:
        """Calculate fuzzy runs similarity."""
        
        # Exact match gets full score
        if runs1 == runs2:
            return 1.0
        
        # Small differences get partial score
        diff = abs(runs1 - runs2)
        if diff == 1:
            return 0.7
        elif diff == 2:
            return 0.4
        elif diff <= 4:
            return 0.2
        
        return 0.0
    
    def find_matches(self, use_llm_config: bool = True) -> List[Dict]:
        """Find matches using hybrid approach."""
        
        if use_llm_config and not self.config:
            self.config = self.generate_llm_configuration()
        elif not use_llm_config and not self.config:
            self.config = self._fallback_configuration()
        elif not self.config:
            self.config = self._fallback_configuration()
        
        # Extract fingerprints
        nvplay_fps, decimal_fps = self.extract_fingerprints()
        
        matches = []
        threshold = self.config.similarity_threshold
        
        logger.info(f"Finding matches with threshold: {threshold}")
        logger.info(f"Using {'LLM' if use_llm_config else 'fallback'} configuration")
        
        total_comparisons = len(nvplay_fps) * len(decimal_fps)
        comparisons_done = 0
        
        for nvplay_id, nvplay_fp in nvplay_fps.items():
            for decimal_id, decimal_fp in decimal_fps.items():
                similarity = self.calculate_fuzzy_similarity(nvplay_fp, decimal_fp)
                
                comparisons_done += 1
                if comparisons_done % 1000 == 0:
                    logger.info(f"Progress: {comparisons_done}/{total_comparisons} comparisons")
                
                if similarity >= threshold:
                    matches.append({
                        'nvplay_match_id': nvplay_id,
                        'decimal_match_id': decimal_id,
                        'similarity_score': similarity,
                        'confidence': 'high' if similarity > 0.9 else 'medium' if similarity > 0.75 else 'low'
                    })
                    
                    logger.info(f"Match found: {nvplay_id} <-> {decimal_id} (similarity: {similarity:.3f})")
        
        logger.info(f"Found {len(matches)} matches using hybrid approach")
        return matches
    
    def _parse_ball_number(self, ball_str: str) -> Dict[str, int]:
        """Parse ball number format."""
        try:
            if '.' in str(ball_str):
                over, ball = str(ball_str).split('.')
                return {'over': int(float(over)), 'ball': int(ball)}
            else:
                ball_num = int(ball_str)
                over = (ball_num - 1) // 6 + 1
                ball = ((ball_num - 1) % 6) + 1
                return {'over': over, 'ball': ball}
        except:
            return {'over': 0, 'ball': 0}
    
    def _fallback_configuration(self) -> HybridConfig:
        """Fallback configuration when LLM is unavailable."""
        return HybridConfig(
            column_mapping={
                "nvplay": {
                    "match_id": "Match",
                    "over": "Over",
                    "ball": "Ball",
                    "batter": "Batter",
                    "bowler": "Bowler",
                    "runs": "Runs",
                    "innings": "Innings"
                },
                "decimal": {
                    "match_id": "date",  # Use date as identifier
                    "over": "over",
                    "ball": "delivery",
                    "batter": "batsman",
                    "bowler": "bowler",
                    "runs": "runs",
                    "innings": "innings"
                }
            },
            similarity_threshold=0.55,  # Lower threshold for fallback
            fingerprint_length=15,     # Shorter fingerprint for better matching
            name_normalization_rules=["remove_dots", "uppercase", "remove_spaces"],
            weight_factors={"player_names": 0.4, "runs_pattern": 0.3, "ball_sequence": 0.3},
            reasoning="Fallback configuration based on manual analysis of actual data columns",
            confidence=0.6
        )


def hybrid_align_matches(nvplay_path: str, decimal_path: str, openai_api_key: Optional[str] = None,
                        output_path: str = "hybrid_aligned_matches.csv") -> List[Dict]:
    """
    Convenience function for hybrid match alignment.
    
    Args:
        nvplay_path: Path to NVPlay CSV file
        decimal_path: Path to decimal CSV file
        openai_api_key: OpenAI API key (optional, auto-detected if not provided)
        output_path: Output CSV file path
        
    Returns:
        List of matched pairs
        
    Note:
        If openai_api_key is None, the function will automatically try to detect
        the API key from env_manager, environment variables, or .env file.
    """
    aligner = HybridMatchAligner(nvplay_path, decimal_path, openai_api_key)
    matches = aligner.find_matches(use_llm_config=aligner.openai_api_key is not None)
    
    # Save results
    if matches:
        df = pd.DataFrame(matches)
        df.to_csv(output_path, index=False)
        logger.info(f"Saved {len(matches)} matches to {output_path}")
    
    return matches


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Hybrid cricket match alignment")
    parser.add_argument("nvplay_file", help="NVPlay CSV file path")
    parser.add_argument("decimal_file", help="Decimal CSV file path")
    parser.add_argument("--api-key", help="OpenAI API key (optional)")
    parser.add_argument("--output", default="hybrid_aligned_matches.csv", help="Output CSV file")
    
    args = parser.parse_args()
    
    logging.basicConfig(level=logging.INFO)
    hybrid_align_matches(args.nvplay_file, args.decimal_file, args.api_key, args.output) 